{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9047283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook can be used to produce unfolded results, to be used as input for UnfoldingPlot.ipynb.\n",
    "# Prerequisites: Full set of numpy toys, generated by ToysROOTtoNumpy.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d4ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipynb.fs.full.CoefficientsCalcPlus import GetCoefficientsFlux\n",
    "from ipynb.fs.full.CoefficientsCalcPlus import get_normalization\n",
    "import sklearn.linear_model\n",
    "import sklearn.linear_model as linear_model\n",
    "import scipy\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import os\n",
    "from matplotlib.pyplot import figure\n",
    "import random as rnd\n",
    "import matplotlib.ticker as ticker\n",
    "#import cvxpy as cp\n",
    "import uproot4 as uproot\n",
    "\n",
    "def rebin(arr, factor):\n",
    "    new_size = arr.size // factor\n",
    "    remainder = arr.size % factor\n",
    "    \n",
    "    if remainder != 0:\n",
    "        arr = arr[:-remainder]\n",
    "        \n",
    "    return np.sum(arr.reshape(-1, factor), axis=1)\n",
    "\n",
    "def rebinned_bin_centers(nbins, xmin, xmax, factor):\n",
    "    # Compute the bin widths for the original histogram\n",
    "    bin_width = (xmax - xmin) / nbins\n",
    "    \n",
    "    # Compute the bin edges for the original histogram\n",
    "    edges = np.linspace(xmin, xmax, nbins + 1)\n",
    "    \n",
    "    # Compute the new bin widths after rebinning\n",
    "    new_bin_width = bin_width * factor\n",
    "    \n",
    "    # Compute the number of new bins\n",
    "    new_nbins = int(nbins / factor)\n",
    "    \n",
    "    # Compute the bin edges for the rebinned histogram\n",
    "    new_edges = np.linspace(xmin, xmax, new_nbins + 1)\n",
    "    \n",
    "    # Compute the bin centers for the rebinned histogram\n",
    "    centers = (new_edges[1:] + new_edges[:-1]) / 2\n",
    "    \n",
    "    return centers\n",
    "\n",
    "def shift(toy,energy):\n",
    "    toy = np.roll(toy,energy,axis=-1)\n",
    "    toy[..., -energy:] = 0\n",
    "    return toy\n",
    "\n",
    "#function definitions\n",
    "def chi2sum(reco,folded,recoerror):\n",
    "    res = ((np.array(reco)-np.array(folded))/np.array(recoerror))**2\n",
    "    return res[res != np.inf].sum()\n",
    "\n",
    "def c_norm(trueRidge):\n",
    "    return np.sqrt((trueRidge**2).sum())\n",
    "\n",
    "def GetGaussianRow(energy_bin_centers,target_loc,target_scale,rescaling = 1):\n",
    "    return np.array([scipy.stats.norm.pdf(x, loc = target_loc, scale = target_scale) for x in energy_bin_centers])\n",
    "\n",
    "def integrate(unfolded,rebin_factor):\n",
    "    return np.array(unfolded).sum()*rebin_factor*0.001\n",
    "\n",
    "def curvature(x_ridge,y_ridge,alphas):\n",
    "    fac = 1.\n",
    "\n",
    "    res = x_ridge\n",
    "    sol = y_ridge\n",
    "    dl = np.diff(alphas)\n",
    "    xi = np.log(sol)\n",
    "    rho = np.log(res)\n",
    "    xi_prime = (1/fac)*np.diff(xi)/dl\n",
    "    rho_prime = np.diff(rho)/dl\n",
    "    xi_prime_prime = fac*np.diff(xi_prime)/dl[:-1]\n",
    "    rho_prime_prime = np.diff(rho_prime)/dl[:-1]\n",
    "\n",
    "    curv = 2*(rho_prime[:-1]*xi_prime_prime - rho_prime_prime*xi_prime[:-1])/np.power(np.power(rho_prime[:-1], 2) + np.power(xi_prime[:-1], 2), 3./2)\n",
    "\n",
    "    curvature = plt.plot(alphas[1:-1], curv, \"r\", label = \"Curvature\")\n",
    "    plt.xlabel(\"Regularisation strength\")\n",
    "    plt.ylabel(\"L-curve Curvature\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show(curvature)\n",
    "    \n",
    "    maxCurv = np.max(curv[~np.isnan(curv)])\n",
    "    num = alphas[1:-1][curv == maxCurv][0]\n",
    "    print(f'Optimal regularisation strength = {num}')\n",
    "    return num\n",
    "\n",
    "def unfold(smearing,reco,alpha_val,modified=False):\n",
    "    if modified:\n",
    "        print(\"modified\")\n",
    "        unfolded = cp.Variable(len(reco))\n",
    "        obj = cp.Minimize(cp.sum_squares(smearing @ unfolded - reco) + alpha_val * cp.norm(unfolded,2.5))\n",
    "        #obj = cp.Minimize(cp.sum_squares(smearing @ unfolded - reco) + alpha_val * cp.tv(unfolded))\n",
    "        prob = cp.Problem(obj)\n",
    "        prob.solve()\n",
    "        unfolded = unfolded.value\n",
    "        return unfolded\n",
    "    else:\n",
    "        clf = sklearn.linear_model.Ridge(alpha=alpha_val,fit_intercept=False)\n",
    "        clf.fit(smearing,reco)\n",
    "        res = clf.coef_\n",
    "        return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec8e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FlexUnfold(rebin_factor,energy,energy_width,input_flux_alpha=-1,smearing_flag=True):\n",
    "    if input_flux_alpha == -1:\n",
    "        flux_alpha_flag = False\n",
    "    else:\n",
    "        flux_alpha_flag = True\n",
    "    flux_alpha_flag = False if input_flux_alpha == -1 else True\n",
    "    \n",
    "    flux_alpha = input_flux_alpha if flux_alpha_flag else 1e-12\n",
    "    \n",
    "    ## Calling this creates a 900 x 58 x (bins) numpy array containing 900 toys ready for building a virtual flux with center = energy.\n",
    "    coeffs, std = GetCoefficientsFlux(1e-3*energy,1e-3*energy_width,flux_alpha,model=sklearn.linear_model.Ridge,years=1)\n",
    "    coeffs = np.array(coeffs)\n",
    "    normalization = get_normalization(coeffs)\n",
    "    energy_bin_centers = rebinned_bin_centers(16000,-8000,8000,rebin_factor)/1000\n",
    "    \n",
    "    ## Get toys\n",
    "    reco_toys = []\n",
    "    for i in range(733):\n",
    "        filename = f'FixedUncNumpyELep/ELepToy{i}.npy'\n",
    "        toy = np.load(filename)\n",
    "        toy = shift(toy,energy)\n",
    "        toy = np.apply_along_axis(rebin,1,toy,rebin_factor)\n",
    "        reco_toys.append(toy)\n",
    "\n",
    "    true_toys = []\n",
    "    for i in range(733):\n",
    "        filename = f'FixedUncNumpyTrueOmega/TrueToy{i}.npy'\n",
    "        toy = np.load(filename)[:,:8000]\n",
    "        pad_width = [(0, 0), (8000, 0)]  # pad 8000 cells of 0 at the start of each row\n",
    "        toy = np.pad(toy, pad_width, mode='constant')\n",
    "        toy = np.apply_along_axis(rebin,1,toy,rebin_factor)\n",
    "        true_toys.append(toy)\n",
    "    \n",
    "    print(\"Done creating correctly binned toys\")\n",
    "    \n",
    "    reco_toys_array = np.array(reco_toys)\n",
    "    true_toys_array = np.array(true_toys)\n",
    "    \n",
    "    reco_array = [np.sum(reco_toys_array[i] * coeffs[:, np.newaxis], axis=0) for i in range(len(reco_toys_array))]\n",
    "    reco_array = np.array(reco_array)\n",
    "\n",
    "    true_array = [np.sum(true_toys_array[i] * coeffs[:, np.newaxis], axis=0) for i in range(len(true_toys_array))]\n",
    "    true_array = np.array(true_array)\n",
    "    \n",
    "    E = (12/201)*1.1e21\n",
    "    nucleons = 1.3954*(2*3*0.574)*1e3/1.66e-27\n",
    "    ftilde = 1e38*(1/(E*nucleons*get_normalization(coeffs)))/(1e-3*rebin_factor)\n",
    "    \n",
    "    reco = ftilde*reco_array.mean(axis=0)\n",
    "    true = ftilde*true_array.mean(axis=0)\n",
    "    \n",
    "    loc = energy\n",
    "    smearing = virtual_smearing(energy,width,1e-12,rebin_factor) if smearing_flag else np.array([GetGaussianRow(energy_bin_centers,loc,std)*0.001*rebin_factor for loc in energy_bin_centers])[:,16000//(2*rebin_factor):]\n",
    "    \n",
    "    alphas = np.logspace(-4,4,1000) ## Sets the range of alpha that will define the L-curve\n",
    "    chi2_array = []\n",
    "    c_norm_array = []\n",
    "    integral_array = []\n",
    "\n",
    "    modified = False # Default\n",
    "\n",
    "    if modified\n",
    "        # This part of the code can be used to explore custom regularization schemes,\n",
    "        # For example, different power law for ||c|| (for Tikhonov it's 2) or others (such as Total Variation)\n",
    "        alphas = np.logspace(-2,0,200) ## fits L2.5\n",
    "        ## alphas = np.logspace(-4,0,200) ## fits TV\n",
    "        for alpha_val in alphas:\n",
    "            unfolded = cp.Variable(len(reco))\n",
    "\n",
    "            obj = cp.Minimize(cp.sum_squares(smearing @ unfolded - reco) + alpha_val * cp.norm(unfolded,2.5))\n",
    "            #obj = cp.Minimize(cp.sum_squares(smearing @ unfolded - reco) + alpha_val * cp.tv(unfolded))\n",
    "            prob = cp.Problem(obj)\n",
    "            prob.solve()\n",
    "\n",
    "            unfolded = unfolded.value\n",
    "\n",
    "            integral = integrate(unfolded,rebin_factor)\n",
    "            folded = np.matmul(smearing,unfolded)\n",
    "            chi2_array.append(chi2sum(reco,folded,recoerror))\n",
    "            c_norm_array.append(c_norm(unfolded))\n",
    "            integral_array.append(-integral)\n",
    "    else:\n",
    "        for alpha_val in alphas:\n",
    "            clf = sklearn.linear_model.Ridge(alpha=alpha_val,fit_intercept=False)\n",
    "            clf.fit(smearing,reco)\n",
    "            trueRidge = clf.coef_\n",
    "            integral = integrate(trueRidge,rebin_factor)\n",
    "            folded = np.matmul(smearing,trueRidge)\n",
    "            #chi2_array.append(chi2sum(reco,folded,recoerror))\n",
    "            c_norm_array.append(c_norm(trueRidge))\n",
    "            integral_array.append(-integral)\n",
    "\n",
    "    optimal = curvature(c_norm_array,-1*np.array(integral_array),alphas)\n",
    "    print(\"optimal = \"+str(optimal))\n",
    "    \n",
    "    print(\"Done calculating optimal regularization parameter\")\n",
    "    \n",
    "    rand_recos_stat = []\n",
    "    for i in range(1000):\n",
    "        filename = f'NumpyELepStat/ELepStatToy{i}.npy' ## These are toys based on 20 years of data\n",
    "        toy = np.load(filename)\n",
    "        toy = shift(toy,energy)\n",
    "        toy = np.apply_along_axis(rebin,1,toy,rebin_factor)\n",
    "        years = 20\n",
    "        virtual_flux = toy.transpose().dot(np.array(coeffs))\n",
    "        E = (12/201)*1.1e21\n",
    "        nucleons = 1.3954*(2*3*0.574)*1e3/1.66e-27\n",
    "        ftilde = 1e38*(1/(E*nucleons*normalization))/(1e-3*rebin_factor)\n",
    "        rand_recos_stat.append(ftilde*virtual_flux/years)\n",
    "    rand_recos_stat = np.array(rand_recos_stat)\n",
    "    \n",
    "    rand_recos_sys = ftilde*reco_array\n",
    "    \n",
    "    print(\"Recos stat length = \"+str(rand_recos_stat.shape))\n",
    "    print(\"Recos sys length = \"+str(rand_recos_sys.shape))\n",
    "    \n",
    "    print(\"Done getting stat and sys toys\")\n",
    "    \n",
    "    solutions_sys = np.array([unfold(smearing,rand_reco,optimal,modified=modified) for rand_reco in rand_recos_sys]).transpose()\n",
    "    solutions_stat = np.array([unfold(smearing,rand_reco,optimal,modified=modified) for rand_reco in rand_recos_stat]).transpose()\n",
    "    \n",
    "    smearing_string = \"GaussianSmearing\"\n",
    "    np.save(\"FixedUncFlexibleUnfoldingResults/\"+smearing_string+\"SystematicUnfoldingEnergy\"+str(energy)+\"BinWidth\"+str(rebin_factor)+\"FluxWidth\"+str(energy_width)+\"Alpha\"+str(flux_alpha)+\".npy\",solutions_sys)\n",
    "    np.save(\"FixedUncFlexibleUnfoldingResults/\"+smearing_string+\"StatisticalUnfoldingEnergy\"+str(energy)+\"BinWidth\"+str(rebin_factor)+\"FluxWidth\"+str(energy_width)+\"Alpha\"+str(flux_alpha)+\".npy\",solutions_stat)\n",
    "    np.save(\"FixedUncFlexibleUnfoldingResults/\"+smearing_string+\"TrueEnergy\"+str(energy)+\"BinWidth\"+str(rebin_factor)+\"FluxWidth\"+str(energy_width)+\"Alpha\"+str(flux_alpha)+\".npy\",true)\n",
    "    \n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8406ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = 500\n",
    "rebin_factor = 40\n",
    "width = 70\n",
    "years = 20\n",
    "flux_alpha = 1e-12\n",
    "\n",
    "modes = ['CCQE','RES','2p2h','Other']\n",
    "modes_arrays = [np.load(\"Mode\"+modes[i]+\"Numpy_20Years.npy\") for i in range(len(modes))] #Generated in ToysROOTtoNumpy.ipynb\n",
    "\n",
    "for energy in [500,625,750,875,1000]: #[500,625,750,875,1000]\n",
    "    for rebin_factor in [40,60,80,100]: #[40,60,80,100]\n",
    "        for width in [70,100,130]: #[70,100,130]\n",
    "            print('('+str(energy)+','+str(width)+','+str(rebin_factor)+')')\n",
    "            FlexUnfold(rebin_factor,energy,width,input_flux_alpha=1e-12,smearing_flag=False)\n",
    "            for i in range(len(modes)):\n",
    "                ## This is for creating mode hists\n",
    "                coeffs, std = GetCoefficientsFlux(1e-3*energy,1e-3*width,flux_alpha,model=sklearn.linear_model.Ridge,years=1)\n",
    "                coeffs = np.array(coeffs)\n",
    "                normalization = get_normalization(coeffs)\n",
    "\n",
    "                E = (12/201)*1.1e21\n",
    "                nucleons = 1.3954*(2*3*0.574)*1e3/1.66e-27\n",
    "                ftilde = 1e38*(1/(E*nucleons*get_normalization(coeffs)))/(1e-3*rebin_factor*years)\n",
    "\n",
    "                true_res = rebin(ftilde*np.sum(modes_arrays[i] * coeffs[:, np.newaxis], axis=0),rebin_factor)\n",
    "                np.save(\"UnfoldingResults/GaussianSmearingTrueEnergy\"+str(energy)+\"BinWidth\"+str(rebin_factor)+\"FluxWidth\"+str(width)+\"Mode\"+modes[i]+\"Alpha\"+str(flux_alpha)+\".npy\",true_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
