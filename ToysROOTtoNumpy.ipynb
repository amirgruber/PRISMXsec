{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc0e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is used to turn ROOT toys to numpy arrays,\n",
    "# to be used in NumpyToysToMeasurements.ipynb or IntegratedXSec.ipynb\n",
    "# Separated into parts (with some overlaps and repetitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07a5b66",
   "metadata": {},
   "source": [
    "# Integrated cross section - 4 GeV cut toys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecddda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites:\n",
    "# 1) norms.txt - a file with the estimated yearly event rate according to the run plan specified in the paper.\n",
    "# 2) Gaussian fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "294d4804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ROOT\n",
    "import numpy as np\n",
    "import uproot4 as uproot\n",
    "from ipynb.fs.full.CoefficientsCalcPlus import GetCoefficientsFlux\n",
    "from ipynb.fs.full.CoefficientsCalcPlus import get_normalization\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import inspect\n",
    "#plt.style.use('seaborn-colorblind')\n",
    "\n",
    "%jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb6ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment:\n",
    "# Since toy production tends to fail occasionally due to grid issues, I examined the output files to figure out a threshold over which all files are successful productions.\n",
    "# In any case, had I included working toys, the conversion to .npy process would fail. This should be done manually for one's set of toys.\n",
    "\n",
    "toy_files = []\n",
    "min_size = 13255*1024 # Should be updated to set a threshold, and see comment above\n",
    "directory = \"IntegratedROOTToys/\"\n",
    "\n",
    "sizes = []\n",
    "for file in os.listdir(directory):\n",
    "    size = os.path.getsize(os.path.join(directory,file))\n",
    "    sizes.append(size)\n",
    "    if size < min_size:\n",
    "        continue\n",
    "    if file.startswith(\"Toy\"):\n",
    "        toy_files.append(directory+file)\n",
    "plt.plot(sorted(sizes)[::-1])\n",
    "toy_nums = [toy_files[i].replace(\".\",\"y\").split(\"y\")[3] for i in range(len(toy_files))]\n",
    "\n",
    "normalization = open(\"norms.txt\", \"r\").read().split(\"\\n\")[:-1]\n",
    "normalization = np.array([float(n) for n in normalization])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for toy in range(len(toy_files)):\n",
    "    toy_res = []\n",
    "    if toy%100 == 0:\n",
    "        print(toy)\n",
    "    toy_file = ROOT.TFile.Open(toy_files[toy],\"read\")\n",
    "    for oa_bin in range(58):\n",
    "        h = toy_file.Get('OmegaRecoHistToy'+toy_nums[toy]+'OAB'+str(oa_bin+1))\n",
    "        entries = 1e7 if oa_bin+1!=56 else 9e6 # This was used since in our generated simulation, off-axis bin 56 had 9e6 events instead of 1e7 (due to a technical issue)\n",
    "        h.Scale(normalization[oa_bin]/entries)\n",
    "        toy_res.append([h.GetBinContent(i) for i in range(1,16000+1)])\n",
    "    np.save(\"NumpyOmega4000CutFixed/OmegaToy\"+str(toy),np.array(toy_res))\n",
    "    toy_file.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_res = np.array([np.array([np.array(np.load(\"NumpyOmega4000CutFixed/OmegaToy\"+str(k)+\".npy\")[i]) for i in range(58)]) for k in range(len(toy_files))])\n",
    "np.save(\"NumpyOmega4000CutFixed/FullResults.npy\",full_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b49328c",
   "metadata": {},
   "source": [
    "# Integrated cross section - no cut on visible energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc9569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ipynb.fs.full.CoefficientsCalcPlus import GetCoefficientsFlux\n",
    "from ipynb.fs.full.CoefficientsCalcPlus import get_normalization\n",
    "import sklearn.linear_model as linear_model\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_toy_files(folder_path):\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter out files that match the pattern ELepToy#.npy\n",
    "    toy_files = sorted([f for f in files if f.startswith('ELepToy') and f.endswith('.npy')], key=lambda x: int(x[7:-4]))\n",
    "    \n",
    "    # Load each numpy file and store it in a list\n",
    "    toy_arrays = [np.load(os.path.join(folder_path, f)) for f in toy_files]\n",
    "    \n",
    "    # Stack all arrays along a new first axis\n",
    "    merged_array = np.stack(toy_arrays, axis=0)\n",
    "    \n",
    "    return merged_array\n",
    "\n",
    "folder_path = 'NumpyELep' #Folder where ELep toys are stored\n",
    "merged_array = merge_toy_files(folder_path)\n",
    "print(merged_array.shape)  # Print the shape of the merged array to verify\n",
    "\n",
    "np.save('NumpyELep/full_res',merged_array)\n",
    "full_res_no_cut = merged_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a02085",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = {0.07:{0.5:30288,0.75:16134,1:29554,1.25:23129,1.5:22920,1.75:22516,2:25490},0.1:{0.5:28604,0.75:17160,1:12196,1.25:29728,1.5:19473},0.078:{0.75:27454}}\n",
    "loc = 0.75\n",
    "width = 0.078\n",
    "locstring = str(loc).replace(\".\",\"\")\n",
    "widthstring = str(width).replace(\".\",\"\")\n",
    "xsecs = {}\n",
    "for width in seeds:\n",
    "    xsecs[width] = {}\n",
    "    for loc in seeds[width]:\n",
    "        locstring = str(loc).replace(\".\",\"\")\n",
    "        widthstring = str(width).replace(\".\",\"\")\n",
    "        file = ROOT.TFile.Open(\"NuWro/test\"+locstring+\"l\"+widthstring+\"w/flat_test\"+locstring+\"l\"+widthstring+\"w_Ar_SF_numu_NuWroOut_\"+str(seeds[width][loc])+\".root\")\n",
    "        t = file.Get(\"FlatTree_VARS\")\n",
    "        for event in t:\n",
    "            xsecs[width][loc] = 1e6*event.fScaleFactor\n",
    "            break\n",
    "        file.Close()\n",
    "\n",
    "vals = [xsecs[0.07][x] for x in xsecs[0.07].keys()]\n",
    "locs = xsecs[0.07].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13960b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsec_no_cut = []\n",
    "dxsec_sys_no_cut = []\n",
    "dxsec_stat_no_cut = []\n",
    "energies = np.array([1e3*loc for loc in locs])\n",
    "denergies = []\n",
    "sys_results_no_cut = []\n",
    "stat_results_no_cut = []\n",
    "years = 5\n",
    "\n",
    "full_res_cv_total_no_cut = full_res_no_cut.mean(axis=0).sum(axis=1)\n",
    "res_stat_no_cut = np.array([np.random.poisson(years*full_res_cv_total_no_cut) for i in range(1000)])\n",
    "\n",
    "for energy in energies:\n",
    "    alpha = 1e-12\n",
    "    coeffs, std = GetCoefficientsFlux(1e-3*energy,0.07,alpha,model=linear_model.Ridge,years=1)\n",
    "    norm = get_normalization(coeffs)\n",
    "    \n",
    "    rebin_factor = 1\n",
    "    E = (12/201)*1.1e21\n",
    "    nucleons = 1.3954*(2*3*0.574)*1e3/1.66e-27\n",
    "    ftilde = 1e38*(1/(E*nucleons*get_normalization(coeffs)))/(1e-3*rebin_factor)\n",
    "    \n",
    "    denergies.append(1e3*std)\n",
    "\n",
    "    ## Sys\n",
    "    expanded_coeffs = np.expand_dims(coeffs, axis=1)\n",
    "    result = full_res_no_cut * expanded_coeffs\n",
    "    result = np.sum(result, axis=1)\n",
    "    sys_result = np.sum(result, axis=1)\n",
    "    sys_results_no_cut.append(sys_result)\n",
    "    \n",
    "    xsec_no_cut.append((ftilde*sys_result).mean()*0.001)\n",
    "    \n",
    "    ## Stat\n",
    "    temp_res = res_stat_no_cut @ expanded_coeffs\n",
    "    stat_result = temp_res * ftilde * 0.001 / years\n",
    "    stat_results_no_cut.append(np.squeeze(stat_result,axis=1))\n",
    "\n",
    "sys_results_no_cut = np.array(sys_results_no_cut)\n",
    "stat_results_no_cut = np.array(stat_results_no_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = np.array(xsec_no_cut)\n",
    "true = 1e38*np.array(vals)\n",
    "if energies[0] == 500:\n",
    "    energies = np.array([1e-3*energy for energy in energies])\n",
    "    denergies = np.array([1e-3*denergy for denergy in denergies])\n",
    "\n",
    "## Systematics\n",
    "sys_results_t = sys_results_no_cut.T # Shape: [#toys, #energies]\n",
    "row_sums = np.sum(sys_results_t, axis=1)\n",
    "expanded_sums = np.expand_dims(row_sums, axis=1)\n",
    "sys_results_normed = sys_results_t / expanded_sums\n",
    "sys_results_normed[:,-1] = np.array(row_sums)\n",
    "\n",
    "cov_test = np.cov(sys_results_normed.T)\n",
    "sums_mean = sys_results_no_cut.T.sum(axis=1).mean()\n",
    "#shape = np.sqrt(cov_test.diagonal()[:-1])\n",
    "shape = np.sqrt(cov_test.diagonal()[:-1])/(sys_results_normed.T[:-1,:].mean(axis=1))\n",
    "shape_unc = np.abs(cv*np.append(shape,0))\n",
    "norm_unc = cv*np.sqrt(cov_test[-1,-1])/sums_mean\n",
    "\n",
    "## Statistics\n",
    "stat_unc = np.sqrt(np.diagonal(np.cov(stat_results_no_cut)))\n",
    "\n",
    "## Stat + Shape\n",
    "stat_shape_unc = np.sqrt(stat_unc**2+shape_unc**2)\n",
    "\n",
    "## By the end of this block, cv = reco; centers = x axis; shape_unc and norm_unc are the decomposed uncertainties\n",
    "\n",
    "deco_cov = np.cov(sys_results_normed.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = np.stack([cv,stat_shape_unc,shape_unc])\n",
    "np.save('IntegratedNoCutRes.npy',final_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fc134b",
   "metadata": {},
   "source": [
    "#  ELep toys (systematic) for differential cross section analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6075ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ROOT\n",
    "import numpy as np\n",
    "import uproot4 as uproot\n",
    "from ipynb.fs.full.CoefficientsCalcPlus import GetCoefficientsFlux\n",
    "from ipynb.fs.full.CoefficientsCalcPlus import get_normalization\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import inspect\n",
    "import re\n",
    "#plt.style.use('seaborn-colorblind')\n",
    "\n",
    "%jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment:\n",
    "# Since toy production tends to fail occasionally due to grid issues, I examined the output files to figure out a threshold over which all files are successful productions.\n",
    "# In any case, had I included working toys, the conversion to .npy process would fail. This should be done manually for one's set of toys.\n",
    "\n",
    "toy_files = []\n",
    "min_size = 13255*1024 # Should be updated to set a threshold, and see comment above\n",
    "directory = \"IntegratedROOTToys/\"\n",
    "\n",
    "sizes = []\n",
    "for file in os.listdir(directory):\n",
    "    size = os.path.getsize(os.path.join(directory,file))\n",
    "    sizes.append(size)\n",
    "    if size < min_size:\n",
    "        continue\n",
    "    if file.startswith(\"Toy\"):\n",
    "        toy_files.append(directory+file)\n",
    "plt.plot(sorted(sizes)[::-1])\n",
    "toy_nums = [toy_files[i].replace(\".\",\"y\").split(\"y\")[3] for i in range(len(toy_files))]\n",
    "\n",
    "normalization = open(\"norms.txt\", \"r\").read().split(\"\\n\")[:-1]\n",
    "normalization = np.array([float(n) for n in normalization])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc9f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True toys - they're unused if the analysis doesn't include unfolding\n",
    "for toy in range(len(toy_files)):\n",
    "    toy_res = []\n",
    "    if toy%100 == 0:\n",
    "        print(toy)\n",
    "    toy_file = ROOT.TFile.Open(toy_files[toy],\"read\")\n",
    "    for oa_bin in range(58):\n",
    "        h = toy_file.Get('OmegaTrueHistToy'+toy_nums[toy]+'OAB'+str(oa_bin+1))\n",
    "        h.Scale(normalization[oa_bin]/h.GetEntries())\n",
    "        omega_bins = [h.GetBinCenter(i) for i in range(1,16000+1)]\n",
    "        toy_res.append([h.GetBinContent(i) for i in range(1,16000+1)])\n",
    "    np.save(\"NumpyTrueOmega/TrueToy\"+str(toy),np.array(toy_res))\n",
    "    toy_file.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a95b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELep toys\n",
    "for toy in range(len(toy_files)):\n",
    "    toy_res = []\n",
    "    if toy%100 == 0:\n",
    "        print(toy)\n",
    "    toy_file = ROOT.TFile.Open(toy_files[toy],\"read\")\n",
    "    for oa_bin in range(58):\n",
    "        h = toy_file.Get('ELepHistToy'+toy_nums[toy]+'OAB'+str(oa_bin+1))\n",
    "        h.Scale(normalization[oa_bin]/h.GetEntries())\n",
    "        omega_bins = [h.GetBinCenter(i) for i in range(1,16000+1)]\n",
    "        toy_res.append([h.GetBinContent(i) for i in range(1,16000+1)])\n",
    "    np.save(\"NumpyELep/ELepToy\"+str(toy),np.array(toy_res))\n",
    "    toy_file.Close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd17c1",
   "metadata": {},
   "source": [
    "# ELep toys (statistical) for differential cross section analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d712eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisite: ELep toys in the format \"NumpyELep/ELepToy\"+str(i)+\".npy\", created in the block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af1b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = [np.load(\"NumpyELep/ELepToy\"+str(i)+\".npy\") for i in range(900)]\n",
    "full_res = np.array(full).mean(axis=0)\n",
    "np.save(\"off_axis_ELep_CV_1MeV\",full_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "off_axis_cvs = np.load(\"off_axis_ELep_CV_1MeV.npy\")\n",
    "toys = [np.random.poisson(20*off_axis_cvs) for i in range(1000)]\n",
    "for i in range(len(toys)):\n",
    "    np.save(f'NumpyELepStat/ELepStatToy{i}.npy',toys[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c19668",
   "metadata": {},
   "source": [
    "# Mode histograms (CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2fe2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block creates .npy files that store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e499d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "path = '/eos/project-n/neutrino-generators/generatorOutput/NuWro/PRISM_studies/SF/proj'\n",
    "\n",
    "for i in range(1,59):\n",
    "    for f in os.listdir(path+str(i)):\n",
    "        if f.startswith('flat') and \"flat\" in f and f.endswith('.root'):\n",
    "        #if True:\n",
    "            if os.path.getsize(path+str(i)+\"/\"+f) > 1000:\n",
    "                files.append(f)\n",
    "                break\n",
    "\n",
    "files = [path+str(i+1)+\"/\"+files[i] for i in range(58)]\n",
    "\n",
    "path = '../SWAN_projects/XSec_ROOT/TTreeMerges/'\n",
    "files = [\"../XSec_ROOT/TTreeMerges/proj\"+str(i+1)+\"_merged.root\" for i in range(58)]\n",
    "\n",
    "coeffs, std = GetCoefficientsFlux(0.75,0.07,1e-12,model=sklearn.linear_model.Ridge,years=1)\n",
    "coeffs = np.array(coeffs)\n",
    "norm = get_normalization(coeffs)\n",
    "years = 20\n",
    "res = [] #[toy][omega bin]\n",
    "rebin = 60\n",
    "omega_bins = [rebin*i+rebin/2 for i in range(int(-8000/rebin),int(8000/rebin))]\n",
    "normalization = open(\"norms.txt\", \"r\").read().split(\"\\n\")[:-1]\n",
    "normalization = np.array([float(n) for n in normalization])\n",
    "\n",
    "total_Nbins = 16000\n",
    "bin_min = -8000\n",
    "bin_max = 8000\n",
    "\n",
    "modes = {\"CCQE\": \"Mode == 1\",\n",
    "         \"2p2h\": \"Mode == 2\",\n",
    "         \"RES\": \"Mode == 11 || Mode == 12 || Mode == 13\",\n",
    "         \"Other\": \"Mode != 1 && Mode != 2 && Mode != 11 && Mode != 12 && Mode != 13\"}\n",
    "\n",
    "reco_hist = ROOT.TH1F(\"reco\",\"reco\",total_Nbins,bin_min,bin_max)\n",
    "true_hist = ROOT.TH1F(\"true\",\"true\",total_Nbins,bin_min,bin_max)\n",
    "mode_hists = [ROOT.TH1F(mode,mode,total_Nbins,bin_min,bin_max) for mode in modes]\n",
    "\n",
    "modes_arrays = [[],[],[],[]]\n",
    "bins = 58\n",
    "for i in range(bins):\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "    file = ROOT.TFile.Open(files[i],\"read\")\n",
    "    reco_added = ROOT.TH1F(\"reco_added\"+str(i),\"added\",total_Nbins,bin_min,bin_max)\n",
    "    true_added = ROOT.TH1F(\"true_added\"+str(i),\"added\",total_Nbins,bin_min,bin_max)\n",
    "    modes_added = [ROOT.TH1F(mode+\"_added\"+str(i),\"added\",total_Nbins,bin_min,bin_max) for mode in modes]\n",
    "    t = file.Get(\"FlatTree_VARS\")\n",
    "    t.Project(\"reco_added\"+str(i),\"750-ELep\") #reco\n",
    "    t.Project(\"true_added\"+str(i),\"Enu_true-ELep\") #true\n",
    "    reco_added.Scale(years*normalization[i]/t.GetEntries())\n",
    "    true_added.Scale(years*normalization[i]/t.GetEntries())\n",
    "    for mode in modes:\n",
    "        t.Project(mode+\"_added\"+str(i),\"Enu_true-ELep\",modes[mode])\n",
    "    cnt = 0\n",
    "    for mode_added in modes_added:\n",
    "        mode_added.Scale(years*normalization[i]/t.GetEntries())\n",
    "        modes_arrays[cnt].append([mode_added.GetBinContent(j) for j in range(1,mode_added.GetNbinsX()+1)])\n",
    "        cnt += 1\n",
    "    for j in range(total_Nbins):\n",
    "        reco_added.SetBinError(j,np.sqrt(reco_added.GetBinContent(j)))\n",
    "    reco_hist.Add(reco_added,coeffs[i])\n",
    "    true_hist.Add(true_added,coeffs[i])\n",
    "    for j in range(len(mode_hists)):\n",
    "        mode_hists[j].Add(modes_added[j],coeffs[i])\n",
    "    file.Close()\n",
    "reco_hist.Rebin(rebin)\n",
    "true_hist.Rebin(rebin)\n",
    "for mode_hist in mode_hists:\n",
    "    mode_hist.Rebin(rebin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(list(modes.keys())[i])\n",
    "    name = \"Mode\"+str(list(modes.keys())[i])+\"Numpy_20Years\"\n",
    "    print(name)\n",
    "    np.save(name,np.array(modes_arrays[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create numpy arrays of -Elep for each off-axis angle\n",
    "files = []\n",
    "path = '/eos/project-n/neutrino-generators/generatorOutput/NuWro/PRISM_studies/SF/proj'\n",
    "\n",
    "for i in range(1,59):\n",
    "    for f in os.listdir(path+str(i)):\n",
    "        if f.startswith('flat') and \"flat\" in f and f.endswith('.root'):\n",
    "        #if True:\n",
    "            if os.path.getsize(path+str(i)+\"/\"+f) > 1000:\n",
    "                files.append(f)\n",
    "                break\n",
    "\n",
    "files = [path+str(i+1)+\"/\"+files[i] for i in range(58)]\n",
    "\n",
    "path = '../SWAN_projects/XSec_ROOT/TTreeMerges/'\n",
    "files = [\"../XSec_ROOT/TTreeMerges/proj\"+str(i+1)+\"_merged.root\" for i in range(58)]\n",
    "\n",
    "years = 20\n",
    "res = [] #[toy][omega bin]\n",
    "rebin = 60\n",
    "omega_bins = [rebin*i+rebin/2 for i in range(int(-8000/rebin),int(8000/rebin))]\n",
    "normalization = open(\"norms.txt\", \"r\").read().split(\"\\n\")[:-1]\n",
    "normalization = np.array([float(n) for n in normalization])\n",
    "\n",
    "total_Nbins = 16000\n",
    "bin_min = -8000\n",
    "bin_max = 8000\n",
    "\n",
    "modes = {\"CCQE\": \"Mode == 1\",\n",
    "         \"2p2h\": \"Mode == 2\",\n",
    "         \"RES\": \"Mode == 11 || Mode == 12 || Mode == 13\",\n",
    "         \"Other\": \"Mode != 1 && Mode != 2 && Mode != 11 && Mode != 12 && Mode != 13\"}\n",
    "\n",
    "mode_hists = [ROOT.TH1F(mode,mode,total_Nbins,bin_min,bin_max) for mode in modes]\n",
    "\n",
    "modes_arrays = [[],[],[],[]]\n",
    "bins = 58\n",
    "for i in range(bins):\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "    file = ROOT.TFile.Open(files[i],\"read\")\n",
    "    modes_added = [ROOT.TH1F(mode+\"_added\"+str(i),\"added\",total_Nbins,bin_min,bin_max) for mode in modes]\n",
    "    t = file.Get(\"FlatTree_VARS\")\n",
    "    for mode in modes:\n",
    "        t.Project(mode+\"_added\"+str(i),\"-ELep\",modes[mode])\n",
    "    cnt = 0\n",
    "    for mode_added in modes_added:\n",
    "        mode_added.Scale(years*normalization[i]/t.GetEntries())\n",
    "        modes_arrays[cnt].append([mode_added.GetBinContent(j) for j in range(1,mode_added.GetNbinsX()+1)])\n",
    "        cnt += 1\n",
    "    file.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32ff92b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = np.save(\"ModesELepCV.npy\",modes_arrays)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
