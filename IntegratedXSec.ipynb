{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e73e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook can be used to plot our results for the integrated cross section analysis.\n",
    "# Prerequisites:\n",
    "# 1) \"Perfect\" gaussian NuWro files,\n",
    "# NuWro/test\"+locstring+\"l\"+widthstring+\"w/flat_test\"+locstring+\"l\"+widthstring+\"w_Ar_SF_numu_NuWroOut_\"+str(seeds[width][loc])+\".root\n",
    "# And see the relevant block for more details on the format\n",
    "# 2) Thin gaussian NuWro generated .root files, same format\n",
    "# 3) Full set of toys with E_recoil < 4 GeV in the format of a numpy array with shape (N_toys, 58 off-axis bins, 16000 energy bins)\n",
    "# 4) Background rates, given in \"background.txt\" and generated with CalculateBackground.txt.\n",
    "# 5) Prepared results without the E_recoil cut, with shape (3,7) where in the 0 axis,\n",
    "# res[0] = measurement\n",
    "# res[1] = uncertainty (stat+shape)\n",
    "# res[2] = uncertainty (shape only)\n",
    "# Actually 5) is by no means necessary, one could compute this on the go. The limitations of the SWAN configurations in terms of cached memory made it\n",
    "# impossible to load 2 sets of toys in the same sessions so I had to resort to precalculating the results. You could do this calculation using the exact same\n",
    "# code here with simple modifications. In any case the code I used to do this is in ToysROOTtoNumpy.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d10da03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.30/04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from ipynb.fs.full.CoefficientsCalcPlus import GetCoefficientsFlux\n",
    "from ipynb.fs.full.CoefficientsCalcPlus import get_normalization\n",
    "import sklearn.linear_model as linear_model\n",
    "import scipy\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import os\n",
    "import re\n",
    "from matplotlib.pyplot import figure\n",
    "import random as rnd\n",
    "import matplotlib.ticker as ticker\n",
    "#import cvxpy as cp\n",
    "import uproot4 as uproot\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import ROOT\n",
    "from scipy.interpolate import make_interp_spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16b6c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def get_normalization(coeffs):\n",
    "    with uproot.open(\"/eos/home-a/amgruber/SWAN_projects/DUNEPRISM_XSec_SDClone_EditedVersion/Fluxes.ND.root\") as fFluxes :\n",
    "        oa_flux = fFluxes['LBNF_numu_flux'].values()\n",
    "        energy_bins = fFluxes['LBNF_numu_flux'].axis(0).edges() # in GeV\n",
    "        angle_bins = fFluxes['LBNF_numu_flux'].axis(1).edges() # in milliradians\n",
    "    oa_flux = oa_flux.transpose()\n",
    "    first_bin_flux = 8.9769702e-08\n",
    "    norm = (oa_flux[0].sum()*0.01)/first_bin_flux\n",
    "    oa_flux = oa_flux/norm\n",
    "    print(oa_flux[0].sum()*0.01)\n",
    "    oa_flux = oa_flux.transpose()\n",
    "    lin_combo = np.matmul(oa_flux, coeffs)\n",
    "    return lin_combo.sum()*0.01\n",
    "\n",
    "def get_normalization_cutoff(coeffs,cutoff):\n",
    "    # Cutoff in GeV\n",
    "    cutoff_bin = int(cutoff*(800/8))\n",
    "    with uproot.open(\"/eos/home-a/amgruber/SWAN_projects/DUNEPRISM_XSec_SDClone_EditedVersion/Fluxes.ND.root\") as fFluxes :\n",
    "        oa_flux = fFluxes['LBNF_numu_flux'].values()\n",
    "        energy_bins = fFluxes['LBNF_numu_flux'].axis(0).edges() # in GeV\n",
    "        angle_bins = fFluxes['LBNF_numu_flux'].axis(1).edges() # in milliradians\n",
    "    oa_flux = oa_flux.transpose()\n",
    "    first_bin_flux = 8.9769702e-08\n",
    "    norm = (oa_flux[0].sum()*0.01)/first_bin_flux\n",
    "    oa_flux = oa_flux/norm\n",
    "    print(oa_flux[0].sum()*0.01)\n",
    "    oa_flux = oa_flux.transpose()\n",
    "    lin_combo = np.matmul(oa_flux, coeffs)\n",
    "    return np.sum(lin_combo[:cutoff_bin])*0.01\n",
    "\n",
    "def get_gaussian_std(prediction,energy_bin_centers,oa_events):\n",
    "    gfit = optimize.curve_fit(gaussian,energy_bin_centers,prediction)[0]\n",
    "    loc,scale = gfit[0],gfit[1]\n",
    "    return [scale,loc]\n",
    "\n",
    "def gaussian(x,loc,scale):\n",
    "    return (1/(scale*((2*np.pi)**0.5)))*np.exp((-((x-loc)/scale)**2)/2)*rescaling\n",
    "\n",
    "def get_virtual_flux(energy,width,plot=True,alpha=1e-12):\n",
    "    # Get DUNE near detector muon neutrino flux as a function of off-axis angle\n",
    "    with uproot.open(\"Fluxes.ND.root\") as fFluxes :\n",
    "        oa_flux = fFluxes['LBNF_numu_flux'].values()\n",
    "        energy_bins = fFluxes['LBNF_numu_flux'].axis(0).edges() # in GeV\n",
    "        angle_bins = fFluxes['LBNF_numu_flux'].axis(1).edges() # in milliradians\n",
    "\n",
    "    N_target = 1.435e30 #[nucleon]\n",
    "    E = 3.62e19 #[POT per year]\n",
    "    epsilon = 1\n",
    "\n",
    "    target_loc = 1e-3*energy\n",
    "    target_scale = 1e-3*width\n",
    "    rescaling = oa_flux.max()\n",
    "    print(rescaling)\n",
    "    energy_bin_centers = np.add(energy_bins[:-1], energy_bins[1:])/2.\n",
    "    target_flux = [scipy.stats.norm.pdf(x, loc = target_loc, scale = target_scale)*rescaling for x in energy_bin_centers] #here we should scale the gaussian\n",
    "\n",
    "    clf = linear_model.Ridge(alpha=alpha,fit_intercept=False) #when fit_intercept=False OA(dot)x = predict(x)\n",
    "    clf.fit(oa_flux,target_flux)\n",
    "    x_ridge = clf.coef_\n",
    "\n",
    "    if plot==True:\n",
    "        #figure(figsize=(8, 6))\n",
    "        plt.plot(energy_bin_centers, target_flux, label = \"Target Flux\")\n",
    "        plt.plot(energy_bin_centers, clf.predict(oa_flux), label = \"Virtual Flux\")\n",
    "        plt.xlabel(r\"E$_{\\nu}$ [GeV]\")\n",
    "        #plt.xlim([0, 1.5])\n",
    "\n",
    "        plt.legend();\n",
    "        plt.grid(True, color = \"grey\", linewidth = \"1\", linestyle = \"-\")\n",
    "        plt.show()\n",
    "    \n",
    "    return energy_bin_centers, clf.predict(oa_flux)\n",
    "\n",
    "def shift(toy,energy):\n",
    "    toy = np.roll(toy,energy,axis=-1)\n",
    "    toy[..., -energy:] = 0\n",
    "    return toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch 70 MeV gaussian cross section (using fScaleFactor, which is a NuWro output)\n",
    "# Seeds are required using the naming convention we used in our NuWro-generated .root files and should be updated manually\n",
    "\n",
    "seeds = {0.07:{0.5:30288,0.75:16134,1:29554,1.25:23129,1.5:22920,1.75:22516,2:25490},0.1:{0.5:28604,0.75:17160,1:12196,1.25:29728,1.5:19473},0.078:{0.75:27454}}\n",
    "loc = 0.75\n",
    "width = 0.078\n",
    "locstring = str(loc).replace(\".\",\"\")\n",
    "widthstring = str(width).replace(\".\",\"\")\n",
    "xsecs = {}\n",
    "for width in seeds:\n",
    "    xsecs[width] = {}\n",
    "    for loc in seeds[width]:\n",
    "        locstring = str(loc).replace(\".\",\"\")\n",
    "        widthstring = str(width).replace(\".\",\"\")\n",
    "        file = ROOT.TFile.Open(\"NuWro/test\"+locstring+\"l\"+widthstring+\"w/flat_test\"+locstring+\"l\"+widthstring+\"w_Ar_SF_numu_NuWroOut_\"+str(seeds[width][loc])+\".root\")\n",
    "        t = file.Get(\"FlatTree_VARS\")\n",
    "        for event in t:\n",
    "            xsecs[width][loc] = 1e6*event.fScaleFactor\n",
    "            break\n",
    "        file.Close()\n",
    "\n",
    "vals = [xsecs[0.07][x] for x in xsecs[0.07].keys()]\n",
    "locs = xsecs[0.07].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd9884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the (N_toys, 58 off-axis bins, 16000 energy bins) numpy array which contains the full set of toys required for simulating the uncertainties\n",
    "\n",
    "full_res = np.load(\"../FluxTest/NumpyOmega4000CutFixed/FullResults.npy\")\n",
    "\n",
    "# Load the background\n",
    "\n",
    "background = np.loadtxt(\"background.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cross sections based on full_res \n",
    "\n",
    "xsec = []\n",
    "dxsec_sys = []\n",
    "dxsec_stat = []\n",
    "energies = np.array([1e3*loc for loc in locs])\n",
    "denergies = [] # Gaussian widths\n",
    "sys_results = []\n",
    "stat_results = []\n",
    "years = 5\n",
    "\n",
    "full_res_cv_total = full_res.mean(axis=0).sum(axis=1)\n",
    "res_stat = np.array([np.random.poisson(years*full_res_cv_total) for i in range(1000)])\n",
    "\n",
    "for energy in energies:\n",
    "    alpha = 1e-12\n",
    "    coeffs, std = GetCoefficientsFlux(1e-3*energy,0.07,alpha,model=linear_model.Ridge,years=1)\n",
    "    norm = get_normalization(coeffs)\n",
    "    \n",
    "    # Normalization\n",
    "    rebin_factor = 1\n",
    "    E = (12/201)*1.1e21\n",
    "    nucleons = 1.3954*(2*3*0.574)*1e3/1.66e-27\n",
    "    ftilde = 1e38*(1/(E*nucleons*get_normalization_cutoff(coeffs,4)))/(1e-3*rebin_factor)\n",
    "    \n",
    "    denergies.append(1e3*std)\n",
    "    \n",
    "    ## Sys\n",
    "    expanded_coeffs = np.expand_dims(coeffs, axis=1)\n",
    "    expanded_coeffs = np.expand_dims(coeffs*(1-background), axis=1)\n",
    "    result = full_res * expanded_coeffs\n",
    "    result = np.sum(result, axis=1)\n",
    "    sys_result = np.sum(result, axis=1)\n",
    "    sys_results.append(sys_result)\n",
    "    \n",
    "    xsec.append((ftilde*sys_result).mean()*0.001)\n",
    "    \n",
    "    ## Stat\n",
    "    temp_res = res_stat @ expanded_coeffs\n",
    "    stat_result = temp_res * ftilde * 0.001 / years\n",
    "    stat_results.append(np.squeeze(stat_result,axis=1))\n",
    "\n",
    "sys_results = np.array(sys_results)\n",
    "stat_results = np.array(stat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3ecc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = np.array(xsec)\n",
    "true = 1e38*np.array(vals)\n",
    "if energies[0] == 500:\n",
    "    energies = np.array([1e-3*energy for energy in energies])\n",
    "    denergies = np.array([1e-3*denergy for denergy in denergies])\n",
    "\n",
    "## Systematics, using Norm-Shape decomposition\n",
    "sys_results_t = sys_results.T # Shape: [#toys, #energies]\n",
    "row_sums = np.sum(sys_results_t, axis=1)\n",
    "expanded_sums = np.expand_dims(row_sums, axis=1)\n",
    "sys_results_normed = sys_results_t / expanded_sums\n",
    "sys_results_normed[:,-1] = np.array(row_sums)\n",
    "\n",
    "cov_test = np.cov(sys_results_normed.T)\n",
    "sums_mean = sys_results.T.sum(axis=1).mean()\n",
    "shape = np.sqrt(cov_test.diagonal()[:-1])/(sys_results_normed.T[:-1,:].mean(axis=1))\n",
    "shape_unc = np.abs(cv*np.append(shape,0))\n",
    "norm_unc = cv*np.sqrt(cov_test[-1,-1])/sums_mean\n",
    "\n",
    "## Statistics\n",
    "stat_unc = np.sqrt(np.diagonal(np.cov(stat_results)))\n",
    "\n",
    "## Stat + Shape\n",
    "stat_shape_unc = np.sqrt(stat_unc**2+shape_unc**2)\n",
    "\n",
    "## By the end of this block, cv = reco; centers = x axis; shape_unc and norm_unc are the decomposed uncertainties\n",
    "\n",
    "deco_cov = np.cov(sys_results_normed.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecdf62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true cross section, based on thin fluxes (effectively 0.0001 GeV width gaussians)\n",
    "\n",
    "thin_fluxes_path = \"NuWro/\"\n",
    "\n",
    "def process_flat_file(file_path):\n",
    "    values = []\n",
    "    file = ROOT.TFile.Open(file_path, \"READ\")\n",
    "    t = file.Get(\"FlatTree_VARS\")\n",
    "    for event in t:\n",
    "        values.append(1e38 * 1e6 * event.fScaleFactor)\n",
    "        break\n",
    "    file.Close()\n",
    "    return values\n",
    "\n",
    "def convert_folder_name_to_float(folder_name):\n",
    "    digits = re.search(r'test(\\d+)', folder_name).group(1)\n",
    "    return float(f\"{digits[0]}.{digits[1:]}\")\n",
    "\n",
    "def collect_values(target_directory):\n",
    "    all_values = []\n",
    "    folder_floats = []\n",
    "    for item in os.listdir(target_directory):\n",
    "        item_path = os.path.join(target_directory, item)\n",
    "        if os.path.isdir(item_path) and re.match(r'test\\d+', item):\n",
    "            folder_float = convert_folder_name_to_float(item)\n",
    "            folder_floats.append(folder_float)\n",
    "            for file in os.listdir(item_path):\n",
    "                if file.startswith('flat'):\n",
    "                    flat_file_path = os.path.join(item_path, file)\n",
    "                    all_values.extend(process_flat_file(flat_file_path))\n",
    "                    break\n",
    "    return all_values, folder_floats\n",
    "\n",
    "target_directory = thin_fluxes_path+'ThinFluxes'  # Change this to your target directory\n",
    "all_values, folder_floats = collect_values(target_directory)\n",
    "\n",
    "true_thin = [all_values[folder_floats.index(val)] for val in energies]\n",
    "\n",
    "# Spline between datapoints\n",
    "energy_spline = np.linspace(np.array(folder_floats).min(), np.array(folder_floats).max(), 1000)\n",
    "true_spline = make_interp_spline(folder_floats, all_values)(energy_spline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e2eab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get integrated result with no cut\n",
    "\n",
    "nocutres = np.load('../FluxTest/IntegratedNoCutRes.npy')\n",
    "xsec_nocut = nocutres[0]\n",
    "dxsec_stat_shape_nocut = nocutres[1]\n",
    "dxsec_shape_nocut = nocutres[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Set global plotting parameters\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.size'] = 32\n",
    "plt.rcParams['xtick.labelsize'] = 32\n",
    "plt.rcParams['ytick.labelsize'] = 32\n",
    "\n",
    "# Plotting configurations\n",
    "lwidth = 2.5\n",
    "capwidth = 1.5\n",
    "col = 'mediumvioletred'\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', \n",
    "          '#984ea3', '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "# Generate lighter colors for uncertainty bands\n",
    "lighter_colors = [\n",
    "    (*[(1 + c) / 2 for c in mcolors.to_rgba(col)[:3]], mcolors.to_rgba(col)[3]) \n",
    "    for col in colors\n",
    "]\n",
    "\n",
    "# Create a figure with two subplots (main plot and residuals)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, sharex=True, figsize=(12, 8), \n",
    "                               gridspec_kw={'height_ratios': [4, 1]}, dpi=300)\n",
    "plt.gcf().set_facecolor('white')\n",
    "\n",
    "# Residual calculation\n",
    "residuals = -(true_thin - cv)\n",
    "\n",
    "# Plotting the no-cut data (background gray lines)\n",
    "nocutcolor = str(0.4)\n",
    "ax1.errorbar(energies[:-1], xsec_nocut[:-1], xerr=denergies[:-1], yerr=dxsec_stat_shape_nocut[:-1],\n",
    "             color=nocutcolor, fmt='_', linewidth=lwidth, capsize=3, capthick=2, ecolor=nocutcolor)\n",
    "\n",
    "# Adding the legend for the no-cut data\n",
    "legend_label = 'PRISM flux (no cut) \\n Shape (inner) $\\\\bigoplus$ Stat (outer) Unc'\n",
    "ax1.errorbar([0], [0], xerr=[0], yerr=[0], color='black', fmt='_', \n",
    "             label=legend_label, linewidth=lwidth, capsize=2, capthick=capwidth, ecolor='black')\n",
    "\n",
    "# Plot each energy point with error bars\n",
    "for i in range(len(energies) - 1):\n",
    "    # Plot the total uncertainty (lighter color)\n",
    "    ax1.errorbar(energies[:-1][i], cv[:-1][i], yerr=total_uncertainty[:-1][i],\n",
    "                 color=lighter_colors[i], fmt=' ', linewidth=lwidth, capsize=3, \n",
    "                 capthick=capwidth, ecolor=lighter_colors[i], zorder=10)\n",
    "\n",
    "    # Plot statistical and shape uncertainties (darker color)\n",
    "    ax1.errorbar(energies[:-1][i], cv[:-1][i], xerr=denergies[:-1][i], yerr=stat_shape_unc[:-1][i],\n",
    "                 color=colors[i], fmt='_', linewidth=lwidth, capsize=3, \n",
    "                 capthick=capwidth, ecolor=colors[i], zorder=10)\n",
    "    \n",
    "    # Plot residuals with error bars\n",
    "    ax2.errorbar(energies[:-1][i], residuals[:-1][i], yerr=total_uncertainty[:-1][i],\n",
    "                 color=lighter_colors[i], fmt=' ', linewidth=lwidth, capsize=3, \n",
    "                 capthick=capwidth, ecolor=lighter_colors[i], zorder=10)\n",
    "\n",
    "# Plot the true Gaussian flux for reference\n",
    "ax1.errorbar(energies[:-1], true[:-1], xerr=[0.07] * len(true[:-1]), fmt='.', \n",
    "             color='black', label='Perfect Gaussian flux')\n",
    "\n",
    "# Plot the theoretical curve\n",
    "ax1.plot(energy_spline, true_spline, color='black', linestyle='--', \n",
    "         label=r'True ($\\Phi(E_{\\nu}) = \\delta(E_{\\nu}-\\tilde{E}_{\\nu})$)')\n",
    "\n",
    "# Formatting the main plot\n",
    "ax1.set_xlim(0.3, 2)\n",
    "ax1.set_ylim(0, 2.5)\n",
    "ax1.set_ylabel(\"$\\langle \\\\sigma \\\\rangle$ [$10^{-38}\\mathrm{cm}^{2}$]\")\n",
    "ax1.grid(True, color=\"lightgray\", linewidth=0.8, linestyle=\"--\")\n",
    "\n",
    "# Formatting the residuals plot\n",
    "ax2.axhline(y=0, color='black', linestyle='--')\n",
    "ax2.set_ylim(-0.25, 0.25)\n",
    "ax2.set_xlabel(\"$E_{\\\\nu}$ [$\\mathrm{GeV}$]\")\n",
    "ax2.set_ylabel(r\"$\\rm True - PRISM$\")\n",
    "ax2.grid(True, color=\"lightgray\", linewidth=0.8, linestyle=\"--\")\n",
    "\n",
    "# Adding a text annotation\n",
    "ax1.text(0.8, 0.94, r\"DUNE Simulation\", transform=ax1.transAxes, fontsize=18, \n",
    "         color='grey', verticalalignment='bottom', horizontalalignment='left')\n",
    "\n",
    "# Adding the legend with customized order and style\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "order = [0, 2, 1, 3]\n",
    "legend = ax1.legend([handles[idx] for idx in order], [labels[idx] for idx in order], \n",
    "                    fontsize=22, frameon=False, loc='upper left', bbox_to_anchor=(0., 1.05))\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# === Global Plot Settings ===\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.size'] = 30\n",
    "plt.rcParams['xtick.labelsize'] = 28\n",
    "plt.rcParams['ytick.labelsize'] = 28\n",
    "plt.gcf().set_facecolor('white')\n",
    "\n",
    "# === Configuration ===\n",
    "font = 30\n",
    "ticks = np.arange(len(energies) - 1)\n",
    "\n",
    "# === 1️⃣ Statistical Correlation Matrix ===\n",
    "print(\"Plotting Statistical Correlation Matrix...\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "fig.set_facecolor('white')\n",
    "covariance_stat = np.cov(stat_results[:-1, :-1])\n",
    "corrcoef_stat = np.corrcoef(stat_results[:-1, :-1])\n",
    "\n",
    "# Plot the matrix\n",
    "im = ax.imshow(corrcoef_stat, cmap='coolwarm')\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"${energy}$\" for energy in energies[:-1]], rotation=45, fontsize=font - 2)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels([f\"${energy}$\" for energy in energies[:-1]], fontsize=font - 2)\n",
    "ax.set_title(\"Statistical Correlation\", fontsize=font)\n",
    "ax.set_xlabel(\"$E_{\\\\nu}$ [$\\mathrm{GeV}$]\", fontsize=font)\n",
    "ax.set_ylabel(\"$E_{\\\\nu}$ [$\\mathrm{GeV}$]\", fontsize=font)\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.clim(-1, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# === 2️⃣ Systematic Correlation Matrix ===\n",
    "print(\"Plotting Systematic Correlation Matrix...\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "fig.set_facecolor('white')\n",
    "covariance_sys = np.cov(sys_results[:-1, :-1])\n",
    "corrcoef_sys = np.corrcoef(sys_results[:-1, :-1])\n",
    "\n",
    "# Plot the matrix\n",
    "im = ax.imshow(corrcoef_sys, cmap='coolwarm')\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"${energy}$\" for energy in energies[:-1]], rotation=45, fontsize=font - 2)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels([f\"${energy}$\" for energy in energies[:-1]], fontsize=font - 2)\n",
    "ax.set_title(\"Systematic Correlation\", fontsize=font)\n",
    "ax.set_xlabel(\"$E_{\\\\nu}$ [$\\mathrm{GeV}$]\", fontsize=font)\n",
    "ax.set_ylabel(\"$E_{\\\\nu}$ [$\\mathrm{GeV}$]\", fontsize=font)\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.clim(-1, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# === 3️⃣ Total Correlation Matrix ===\n",
    "print(\"Plotting Total Correlation Matrix...\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "fig.set_facecolor('white')\n",
    "covariance_matrix = covariance_stat + covariance_sys\n",
    "sqrt_diagonal = np.sqrt(np.diag(covariance_matrix))\n",
    "correlation_matrix = covariance_matrix / (sqrt_diagonal[:, None] * sqrt_diagonal[None, :])\n",
    "\n",
    "# Plot the matrix\n",
    "im = ax.imshow(correlation_matrix, cmap='coolwarm')\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"${energy}$\" for energy in energies[:-1]], rotation=45, fontsize=font - 2)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels([f\"${energy}$\" for energy in energies[:-1]], fontsize=font - 2)\n",
    "ax.set_title(\"Total Correlation\", fontsize=font)\n",
    "ax.set_xlabel(\"$E_{\\\\nu}$ [$\\mathrm{GeV}$]\", fontsize=font)\n",
    "ax.set_ylabel(\"$E_{\\\\nu}$ [$\\mathrm{GeV}$]\", fontsize=font)\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.clim(-1, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# === 4️⃣ Decomposed Shape and Normalization Covariance ===\n",
    "print(\"Plotting Decomposed Shape and Normalization Covariance...\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "fig.set_facecolor('white')\n",
    "deco_cov = np.cov(sys_results_normed.T)\n",
    "\n",
    "# Plot the matrix\n",
    "im = ax.imshow(deco_cov, cmap='coolwarm')\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"${energy}$\" for energy in energies[:-1]], rotation=45, fontsize=font - 2)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels([f\"${energy}$\" for energy in energies[:-1]], fontsize=font - 2)\n",
    "ax.set_title(\"Decomposed Shape and Normalization Covariance\", fontsize=font)\n",
    "ax.set_xlabel(\"$E_{\\\\nu}$ [$\\mathrm{GeV}$]\", fontsize=font)\n",
    "ax.set_ylabel(\"$E_{\\\\nu}$ [$\\mathrm{GeV}$]\", fontsize=font)\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.clim(-1, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
